{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\KUNAL MEHTA\\\\Desktop\\\\Data Science Training\\\\Projects\\\\Auto-Insurance-Risk-Profiling\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\KUNAL MEHTA\\\\Desktop\\\\Data Science Training\\\\Projects\\\\Auto-Insurance-Risk-Profiling'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AutoInsurance.constants import *\n",
    "from AutoInsurance.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir= config.root_dir,\n",
    "            train_data_path= config.train_data_path,\n",
    "            test_data_path= config.test_data_path,\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from AutoInsurance import logger\n",
    "\n",
    "REFERENCE_DATE = datetime.datetime(2017, 12, 31)\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def calculate_age(self, dob):\n",
    "        '''Compute the age of a person as of December 31, 2017.'''\n",
    "        return REFERENCE_DATE.year - dob.year - ((REFERENCE_DATE.month, REFERENCE_DATE.day) < (dob.month, dob.day))\n",
    "\n",
    "    def map_age_to_category(self, ages):\n",
    "        '''Map ages to categories using vectorized operations.'''\n",
    "        bins = [0, 18, 28, 38, 48, 58, 68, float('inf')]\n",
    "        labels = range(len(bins) - 1)\n",
    "        return pd.cut(ages, bins=bins, labels=labels, right=False)\n",
    "\n",
    "    def impute_with_median(self, df, column, groupby_column):\n",
    "        '''Impute missing values in a column using the median of groups defined by another column.'''\n",
    "        medians = df.groupby(groupby_column, observed=True)[column].transform('median')\n",
    "        df[column] = df[column].fillna(medians)\n",
    "        return df\n",
    "\n",
    "    def prepare_and_clean_data(self, df):\n",
    "        '''Prepare and clean the DataFrame.'''\n",
    "        df[\"date_of_birth\"] = pd.to_datetime(df['date_of_birth'])\n",
    "        df['age'] = df['date_of_birth'].apply(self.calculate_age)\n",
    "        if 'agecat' in df.columns and df['agecat'].isnull().any():\n",
    "            df['agecat'] = self.map_age_to_category(df['age'])\n",
    "        df = self.impute_with_median(df, 'credit_score', 'agecat')\n",
    "        df = self.impute_with_median(df, 'traffic_index', 'area')\n",
    "        df['veh_value'] = np.log(df['veh_value'] + 1)\n",
    "        df['agecat'] = df['agecat'].astype('object')\n",
    "        df['veh_age'] = df['veh_age'].astype('object')\n",
    "        return df\n",
    "\n",
    "    def get_dummies(self, df):\n",
    "        '''Get dummy variables for categorical features.'''\n",
    "        return pd.get_dummies(df, columns=['gender', 'area', 'veh_body', 'agecat', 'veh_age'], drop_first=True)\n",
    "\n",
    "    def transform_for_classification(self, df_2017, df_2018):\n",
    "        '''Transform data for classification.'''\n",
    "        df_2017 = self.get_dummies(df_2017)\n",
    "        df_2018 = self.get_dummies(df_2018)\n",
    "\n",
    "        df_2017['claim'] = df_2017['numclaims'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "        X = df_2017.drop([\"numclaims\", \"claimcst0\", \"claim\"], axis=1)\n",
    "        y = df_2017[\"claim\"]\n",
    "        x_test = df_2018\n",
    "\n",
    "        return X, y, x_test\n",
    "\n",
    "    def transform_for_regression(self, df_2017, df_2018):\n",
    "        '''Transform data for regression.'''\n",
    "        df_2017 = self.get_dummies(df_2017)\n",
    "        df_2018 = self.get_dummies(df_2018)\n",
    "\n",
    "        df_2017['claim'] = df_2017['numclaims'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "        claim_amount_train = df_2017[df_2017['claim'] > 0].copy()\n",
    "        claim_amount_train['amountperclaim'] = np.where(\n",
    "            claim_amount_train['numclaims'] > 0, \n",
    "            claim_amount_train['claimcst0'] / claim_amount_train['numclaims'],\n",
    "            0  \n",
    "        )\n",
    "\n",
    "        claim_amount_train[\"log_amount\"]=(claim_amount_train.amountperclaim+1).apply(np.log)\n",
    "\n",
    "        X_reg = claim_amount_train.drop([\"numclaims\", \"claimcst0\", \"claim\", \"amountperclaim\", \"log_amount\"], axis=1)\n",
    "        y_reg = claim_amount_train[\"log_amount\"]\n",
    "\n",
    "        x_test = df_2018\n",
    "\n",
    "        return X_reg, y_reg, x_test\n",
    "\n",
    "    def load_and_transform_data(self):\n",
    "        '''Load data and apply transformations.'''\n",
    "        df_2017 = pd.read_csv(self.config.train_data_path, parse_dates=True)\n",
    "        df_2018 = pd.read_csv(self.config.test_data_path, parse_dates=True)\n",
    "        \n",
    "        clean_data_2017 = self.prepare_and_clean_data(df_2017)\n",
    "        clean_data_2018 = self.prepare_and_clean_data(df_2018)\n",
    "        \n",
    "        data_2017 = clean_data_2017.drop([\"age\", \"claim_office\", \"pol_number\", \"pol_eff_dt\", \"annual_premium\", \"date_of_birth\"], axis=1)\n",
    "        data_2018 = clean_data_2018.drop([\"quote_number\", \"date_of_birth\", \"age\"], axis=1)\n",
    "        \n",
    "        X_class, y_class, x_test_class = self.transform_for_classification(data_2017, data_2018)\n",
    "        X_reg, y_reg, x_test_reg = self.transform_for_regression(data_2017, data_2018)\n",
    "\n",
    "        logger.info(\"Transformed the data as per required by the models respectively.\")\n",
    "\n",
    "        class_train_data = X_class.copy()\n",
    "        class_train_data['claim'] = y_class\n",
    "        \n",
    "        reg_train_data = X_reg.copy()\n",
    "        reg_train_data['log_amount'] = y_reg\n",
    "\n",
    "        # Save the processed data\n",
    "        class_train_data.to_csv(os.path.join(self.config.root_dir,\"processed_train_class_data.csv\"), index=False)\n",
    "        reg_train_data.to_csv(os.path.join(self.config.root_dir,\"processed_train_reg_data.csv\"), index=False)\n",
    "        x_test_class.to_csv(os.path.join(self.config.root_dir,\"Processed_test_data.csv\"), index=False)\n",
    "        \n",
    "        logger.info(\"Processed files saved to their respective paths\")\n",
    "        \n",
    "        return (X_class, y_class, x_test_class), (X_reg, y_reg, x_test_reg)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-21 16:47:29,827: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-05-21 16:47:29,837: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-05-21 16:47:29,849: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-05-21 16:47:29,851: INFO: common: created directory at: artifacts]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-21 16:47:29,853: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2024-05-21 16:47:30,586: INFO: 4146024108: Transformed the data as per required by the models respectively.]\n",
      "[2024-05-21 16:47:31,225: INFO: 4146024108: Processed files saved to their respective paths]\n"
     ]
    }
   ],
   "source": [
    "config_manager = ConfigurationManager()\n",
    "data_transformation_config = config_manager.get_data_transformation_config()\n",
    "data_transformation = DataTransformation(data_transformation_config)\n",
    "\n",
    "(classification_data, regression_data) = data_transformation.load_and_transform_data()\n",
    "X_class, y_class, x_test_class = classification_data\n",
    "X_reg, y_reg, x_test_reg = regression_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
